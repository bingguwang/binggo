version: '3.5'
# 网络配置
#networks:
#  backend:
#    driver: bridge
#
networks:
  backend:
    driver: overlay

# 服务容器配置
services:
#  etcd: # 自定义容器名称
#    build:
#      context: etcd                    # 指定构建使用的 Dockerfile 文件
#    environment:
#      - TZ=Asia/Shanghai
#      - ALLOW_NONE_AUTHENTICATION=yes
#      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379
#    ports: # 设置端口映射
#      - "2379:2379"
#    networks:
#      - backend
#    restart: always
#
#  etcd-manage:
#    build:
#      context: etcd-manage
#    environment:
#      - TZ=Asia/Shanghai
#    ports:
#      - "7000:8080"                    # 设置容器8080端口映射指定宿主机端口，用于宿主机访问可视化web
#    depends_on: # 依赖容器
#      - etcd                                          # 在 etcd 服务容器启动后启动
#    networks:
#      - backend
#    restart: always
#
#  courseware-rpc: # 自定义容器名称
#    build:
#      context: courseware                 # 指定构建使用的 Dockerfile 文件
#      dockerfile: rpc/Dockerfile
#    environment: # 设置环境变量
#      - TZ=Asia/Shanghai
#    privileged: true
#    volumes:
#      - ./data/log/courseware-rpc:/var/log/go-zero/courseware-rpc
#    ports: # 设置端口映射
#      - "9400:9400"  # 课件服务rpc端口
#    stdin_open: true                     # 打开标准输入，可以接受外部输入
#    tty: true
#    networks:
#      - backend
#    restart: always                      # 指定容器退出后的重启策略为始终重启
#
#  courseware-api: # 自定义容器名称
#    build:
#      context: courseware                  # 指定构建使用的 Dockerfile 文件
#      dockerfile: api/Dockerfile
#    environment: # 设置环境变量
#      - TZ=Asia/Shanghai
#    privileged: true
#    volumes:
#      - ./data/log/courseware-api:/var/log/go-zero/courseware-api
#    ports: # 设置端口映射
#      - "8400:8400"  # 课件服务api端口
#    stdin_open: true                     # 打开标准输入，可以接受外部输入
#    tty: true
#    networks:
#      - backend
#    restart: always                      # 指定容器退出后的重启策略为始终重启

#  user-rpc: # 自定义容器名称
#    build:
#      context: user                 # 指定构建使用的 Dockerfile 文件
#      dockerfile: rpc/Dockerfile
#    environment: # 设置环境变量
#      - TZ=Asia/Shanghai
#    privileged: true
#    volumes:
#      - ./data/log/user-rpc:/var/log/go-zero/user-rpc
#    ports: # 设置端口映射
#      - "9300:9300"  # 课件服务rpc端口
#    stdin_open: true                     # 打开标准输入，可以接受外部输入
#    tty: true
#    networks:
#      - backend
#    restart: always                      # 指定容器退出后的重启策略为始终重启

  user-api: # 自定义容器名称
    image: 192.168.2.130:8111/test/elkdemo-user-api:latest
    build:
      context: user                  # 指定构建使用的 Dockerfile 文件
      dockerfile: api/Dockerfile
    environment: # 设置环境变量
      - TZ=Asia/Shanghai
    privileged: true
    volumes:
      # 把日志文件挂载出来，挂到./data/log/user-api下面，而这个路径又被filebeat挂载到了filebeat容器里以便被filebeat作为input读取
      - ./data/log/user-api:/var/log/go-zero/user-api
    ports: # 设置端口映射
      - "8300:8300"  # 课件服务api端口
    stdin_open: true                     # 打开标准输入，可以接受外部输入
    tty: true
    networks:
      - backend
    restart: always                      # 指定容器退出后的重启策略为始终重启

#  elasticsearch:
#    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.4
##    build: . # docker build创建非root用户
#    user: root # 这里设置了非 root 用户
#    container_name: elasticsearch
#    environment:
#      - TZ=Asia/Shanghai
#      - discovery.type=single-node
#      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
##      - xpack.security.enabled=false
##      - xpack.security.http.ssl.enabled=false
#      - network.host=0.0.0.0  # 添加这一行
#    privileged: true
#    volumes:
#      - ./data/elasticsearch/data:/usr/share/elasticsearch/data
#    ports:
#      - "9200:9200"
#    networks:
#      - backend
#    restart: always

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.4
    container_name: elasticsearch
    user: root
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms256m -Xmx256m"
      - TZ=Asia/Shanghai
    deploy:
      replicas: 1
      placement:
        constraints: [ node.hostname == wbtest2.novalocal ]
    volumes:
      - ./data/elasticsearch/data:/usr/share/elasticsearch/data
    restart: always
    ports:
      - "9200:9200"
      - "9300:9300"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    networks:
      - backend

#  prometheus:
#    build:
#      context: ./prometheus
#    environment:
#      - TZ=Asia/Shanghai
#    privileged: true
#    volumes:
#      - ./prometheus/prometheus.yml:/opt/bitnami/prometheus/conf/prometheus.yml  # 将 prometheus 配置文件挂载到容器里
#      - ./prometheus/target.json:/opt/bitnami/prometheus/conf/targets.json  # 将 prometheus 配置文件挂载到容器里
#    ports:
#      - "9090:9090"                     # 设置容器9090端口映射指定宿主机端口，用于宿主机访问可视化web
#    networks:
#      - backend
#    restart: always
#
#  grafana:
#    build:
#      context: ./grafana
#    environment:
#      - TZ=Asia/Shanghai
#    privileged: true
#    ports:
#      - "3000:3000"
#    networks:
#      - backend
#    restart: always

#  jaeger:
#    build:
#      context: ./jaeger
#    environment:
#      - TZ=Asia/Shanghai
#      - SPAN_STORAGE_TYPE=elasticsearch
#      - ES_SERVER_URLS=http://elasticsearch:9200
#      - LOG_LEVEL=debug
#    privileged: true
#    ports:
#      - "6831:6831/udp"
#      - "6832:6832/udp"
#      - "5778:5778"
#      - "16686:16686"
#      - "4317:4317"
#      - "4318:4318"
#      - "14250:14250"
#      - "14268:14268"
#      - "14269:14269"
#      - "9411:9411"
#    networks:
#      - backend
#    restart: always

  kibana:
    image: docker.elastic.co/kibana/kibana:7.13.4
    container_name: kibana
    environment:
      - elasticsearch.hosts=http://elasticsearch:9200
      - TZ=Asia/Shanghai
    privileged: true
    ports:
      - "5601:5601"
    networks:
      - backend
    restart: always
    depends_on:
      - elasticsearch

  go-stash:
    image: kevinwan/go-stash:1.0 # if you "macOs intel" or "linux amd"
    container_name: go-stash
    environment:
      - TZ=Asia/Shanghai
    privileged: true
    volumes:
      - ./go-stash/go-stash.yml:/app/etc/config.yaml
    networks:
      - backend
    restart: always
#    healthcheck:
#      test: [ "CMD-SHELL", "curl -f http://elasticsearch:9200 || exit 1" ]
#      interval: 30s
#      timeout: 10s
#      retries: 5
#      start_period: 30s
    depends_on:
      - elasticsearch
      - kafka

  filebeat:
    image: elastic/filebeat:7.13.4
    container_name: filebeat
    build:
      context: ./filebeat
    environment:
      - TZ=Asia/Shanghai
    entrypoint: "filebeat -e -strict.perms=false"
    privileged: true
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - ./data/log:/var/lib/docker/containers
    networks:
      - backend
    restart: always
    depends_on:
      - kafka

  zookeeper:
    image: 192.168.2.130:8111/test/bitnami/zookeeper
    container_name: zookeeper
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
      - TZ=Asia/Shanghai
    privileged: true
    networks:
      - backend
    ports:
      - "2181:2181"
    restart: always

  kafka:
    image: 192.168.2.130:8111/test/wurstmeister/kafka:latest
    container_name: kafka
    deploy:
      replicas: 1
      placement:
        constraints: [ node.hostname == wbtest1.novalocal ] # Replace with your actual node hostname
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NUM_PARTITIONS=3 # 分区个数
      - KAFKA_DEFAULT_REPLICATION_FACTOR=2 # 分区副本数
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka3:9092
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - TZ=Asia/Shanghai
      - ALLOW_PLAINTEXT_LISTENER=yes
    restart: always
    volumes:
      - /data/docker-compose/kafka/broker1/logs:/opt/kafka/logs
      - /data/kafka:/kafka
      - /var/run/docker.sock:/var/run/docker.sock
    privileged: true
    networks:
      - backend
    depends_on:
      - zookeeper


  kafka2:
    image: 192.168.2.130:8111/test/wurstmeister/kafka:latest
    container_name: kafka2
    ports:
      - "9094:9092"
    environment:
      - KAFKA_NUM_PARTITIONS=3 # 分区个数
      - KAFKA_DEFAULT_REPLICATION_FACTOR=2 # 分区副本数
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka3:9094
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - TZ=Asia/Shanghai
      - ALLOW_PLAINTEXT_LISTENER=yes
    restart: always
    deploy:
      replicas: 1
      placement:
        constraints: [ node.hostname == wbtest2.novalocal ] # Replace with your actual node hostname
    volumes:
      - /data/docker-compose/kafka/broker1/logs:/opt/kafka/logs
      - /data/kafka:/kafka
      - /var/run/docker.sock:/var/run/docker.sock
    privileged: true
    networks:
      - backend
    depends_on:
      - zookeeper

  kafka3:
    image: 192.168.2.130:8111/test/wurstmeister/kafka:latest
    container_name: kafka3
    ports:
      - "9095:9092"
    environment:
      - KAFKA_NUM_PARTITIONS=3 # 分区个数
      - KAFKA_DEFAULT_REPLICATION_FACTOR=2 # 分区副本数
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka3:9095
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      - TZ=Asia/Shanghai
      - ALLOW_PLAINTEXT_LISTENER=yes
    restart: always
    deploy:
      replicas: 1
      placement:
        constraints: [ node.hostname == wbtest2.novalocal ] # Replace with your actual node hostname
    volumes:
      - /data/docker-compose/kafka/broker1/logs:/opt/kafka/logs
      - /data/kafka:/kafka
      - /var/run/docker.sock:/var/run/docker.sock
    privileged: true
    networks:
      - backend
    depends_on:
      - zookeeper

#  kafka-init为了预先创建好topic而用
  kafka-init:
    image: 192.168.2.130:8111/test/wurstmeister/kafka:latest
    networks:
      - backend
    depends_on:
      - kafka
    command: "sh -c 'sleep 30 && /opt/kafka/bin/kafka-topics.sh --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic courseware-log && exec tail -f /dev/null'"
